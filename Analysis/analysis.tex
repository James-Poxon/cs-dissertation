%!TeX root=../Dissertation.tex
%!TeX bibfile=./analysis.bib




\chapter{Review of Virtualisation}

\section{Terminology \& Definitions}


\subsection{Virtualisation}
Virtualisation as a term originated in the 1960s when IBM workers began work on a project that would allow an IBM model-40 computer to segregate off its memory and allow up to 15 users to use the computer independently at once \citep{Lindquist1966}. Each user would see their own abstract Operating System, separate from the others. Whilst virtualisation has continued in its development from this point onwards, the core functionality and architecture behind Hardware Virtualisation, remain much the same.

Each of these individual logical (as opposed to physical) devices is called a `virtual machine'.

\subsection{Hardware Virtualisation}
\label{subsec:HardwareVirtualisation}
There are a number of different types of virtualisation. This can open the scope for what can and can not be considered as a virtual machine. For the purpose of this report the term `virtualisation' will refer specifically to `hardware based virtualisation', whereby a `virtual machine' is an operating system running on top of another operating system, with the virtualisation task itself being controlled by a `hypervisor' (This is explained in more detail in the next subsection: \ref{subsec:hypervisor}).

This is an important definition to clarify, as often times containerisation (subsection \ref{sec:containerisation}) can be viewed as a type of virtualisation, and other times not. For the purposes of this report, the two definitions must be distinguished as separate things, much like in the report ``Autonomic Orchestration of Containers: Problem Definition and Research Challenges'' \citep{casalicchio2016}, where a clear and defined difference between Hardware Virtualisation and Containerisation is made.

\subsection{Hypervisor}
\label{subsec:hypervisor}
Hardware Virtualisation relies on an underlying software that runs on the already existing OS in order to manage each instance/OS. This software can have a number of different names depending on the origin of the work, and the context. In early work on virtualisation, this software was often referred to simply as a ``control program'' \citep{creasy1981}, but for the purposes of this research, this software will be referred to as a `Hypervisor'. This term is often preferred in practical settings, such as in VMware's online Glossary \citep{vmwareHypervisor}, or in Red Hat's ``What is a hypervisor'' \citep{redhat2021}.



\section{The workings of virtualisation}
Virtualisation works






\chapter{Review of Containerisation}


\section{Terminology \& Definitions}

\subsection{Containerisation}
\label{subsec:containerisation}
Containerisation has become the de-facto term to describe what could also be described as OS-level virtualisation. For the purposes of this report, I will be referring to this technology only as Containerisation, and each individual instance as a container (instead of virtual machine). This is the same approach towards defining containers as taken by Dua et al \citep{dua14} when they have made their own distinction between Containers and Virtual Machines.

\subsection{Container Engine}
\label{Container Engine}
What a hypervisor is to a virtual machine, a container engine is to a container. A container engine sits on the base operating system, much the same as a hypervisor. Where a difference is found however, is in the way it interacts with the base operating system.

Whilst a hypervisor works by running a full operating system on top of the existing one, a container engine works without that upper operating system by using the base operating system as the OS component for each container. Segregation of containers and resource allocation is simply managed by the container engine, so that each container is allocated resources. This can be done dynamically or be static, depending on the use-case.




\section{Developments in containerisation technology}

\subsection{Docker}
An ever more popular implementation of container technology is a software known as Docker. This software is primarily used by (and aimed at) developers, who can use the platform to quickly create and deploy applications for testing. The use of containers is supposed to make managing these applications much easier, and ensures compatibility along the whole development process.
Datanyze (a technology market usage group) report that Docker is currently the second most used Containerisation platform, with 25.34\% market share in Containerisation \citep{datanyze}. 

Docker's Container engine is aptly named Docker Engine, and utilises a client-server architecture \citep[Section: Docker architecture]{DockerOverview}. The server portion of the Docker System is known as the `docker daemon', the Client uses a command line interface to interact with one or more docker daemons. The client and daemon communicate using a `REST API' \citep[Section: The Docker daemon]{DockerOverview}. REST (Representational State Transfer) provides an architecture for web services \citep{W3Architecture2004} that allows them to communicate over HTTP. The protocols within REST are stateless, this means there is no set `state' or session control within the protocol; each command sent to a daemon can be understood as it is, without the need for any outside context to the command being sent.

The Docker Daemon manages `Objects' \citep[Section: Docker objects]{DockerOverview} required for a full Docker system. 'Objects' refers to the containers, the images (Docker images are the instruction sets for Docker containers, not to be confused with OS images, though often the Docker images will include which OS image is to be used).

Docker images are stored in a Docker Registry \citep[Section: Docker registries]{DockerOverview}. By default, the registry is configured to use "Docker Hub" which is a public, open registry that already contains a large number of complete images for use. This registry can be changed however, to point to any location. This behaviour allows a registry to be setup part of a network, and the images can then be 'pulled' or 'run' from the registry using the "docker pull" and "docker run" commands\citep[Section: Docker registries]{DockerOverview}. An image can also be configured on a live container, and then that image pushed to the registry using the "docker push" command \citep[Section: Docker registries]{DockerOverview}.

\subsection{How Docker works}
Docker is written using the 'Go Programming language' \citep[Section: The underlying technology]{DockerOverview}. Go is developed and maintained by Google on an open source liscense, and is roughly based on the C programming language\citep{GoAncestors}. Being based on C gives the programming language the same benefits of any other low level language, being able to make use of functions that are integral to the kernal and operating system. Where go differs is that it is also designed to be be more intuitive and "clutter free" \citep{GoPrinciples}.

\subsubsection{Namespaces}
Docker makes use of a feature of Go that allows further use of a linux kernal feature known as namespaces \citep[Section: Namespaces]{DockerOverview}.
When new containers are created, a set of namespaces are created sepcifically for that container. This means that programs that might otherwise be considered by the kernal to be entirely sperate, are processed together, and vice versa. This in turn allows multiple containers to run processes in isolation that otherwise would have been processed by the kernal together, and also process a number of actions as one whole unit, that otherwise would have been considered seperate tasks to the operating system. This is key to the function of containers, as it allows each container to process tasks as sperate entities, but make use of the same kernal and operating system across all containers.

\subsubsection{Control Groups}
Control groups is another feature of the linux kernal used by Docker. Control groups allow hardware resources to be segrated in a way that limits and further isolates them \citep{corbetControlGroups}. In docker, this is used to segregate parts of memory, logical processors, drive space and network access so that there is no crossover in hardware utilisation between different containers. This is similar to how a hypervisor would segregate resources, but instead this is managed entirely by the kernal.

\chapter{System design and definition}


\section{Maintaining scientific method}
To ensure that results are scientific, variables must be controlled between both of the systems. The first step in this, is ensuring that the topology and configurations for both systems are the same. This can be done by copying the configuration files from one system to the other, ensuring that the system works in the same way for both systems. As the underlying operating system should be a version of Linux for both the virtual machine and the Docker system, this should be relatively easy.

To further ensure that variables are controlled, we need to ensure that the same benchmarks are maintained throughout the testing process, when being used on the \emph{same part of the system}. This means that if one benchmark is used to measure, for example, network latency on a web-server, then the same benchmark should be used to measure the network latency on that same web-server on the mirrored system. It may be necessary to use different benchmarks across the whole system, but this is acceptable as long as all testing is done to a parallel across both systems. The benchmarks to be used will be discussed in more detail in subsection \ref{sub:Benchmarking} (Benchmarking).

\subsection{LAMP System}
In order to make sure that the system is as accurate tom a real-world system as possible, a full LAMP topology will need to be implemented for both the Docker system and the Virtual Machine system. LAMP is the acronym of Linux, Apache, MySQL and PHP, whilst this can technically be run on one system, it is common to separate various functions out onto different logical machines, this generally makes management of these systems easier, and often more streamlined.

\subsection{Benchmarking}
\label{sub:Benchmarking}
Benchmarking software and tools are designed to create a standard output measurement for performance of a computer-based system\citep{fleming1986}.

There are a great number of benchmarking tools available to me for this research, but generally these can be split in discussion along lines of what exactly they are designed to measure. The main split for this research, being the measuring of base compute performance, and of network performance.

\subsubsection{Base Computing Performance}
Base computing performance in this case relates to the performance as a result of the computers ability to process information, and at what rate. Whilst this is tied directly to the processor, RAM, and other hardware, the Operating system itself can also have a large affect on the performance of a system, as it will always take up an amount of utilisation over time. This effect is known as `operating system overhead'. Based on previous research on containers and virtual machines it can be hypothesised that the total Operating System overhead for a container-based system will be smaller than that of Virtual Machines \emph{(when using the same operating system)}. This is simply due to the way that containers utilise one OS for their function (as discussed in subsection \ref{Container Engine}).

\subsubsection{Network Performance}

\subsection{DNS}

\subsection{Webserver}

\subsection{Intranet}

\chapter{How will the system be measured}
%Talk about benchmarks.