%!TeX root=../Dissertation.tex
%!TeX bibfile=./analysis.bib

\chapter{Review of Virtualisation and what it does}

\section{Terminology \& Definitions}

\subsection{Virtualisation}
Virtualisation as a term originated in the 1960s when IBM workers began work on a project that would allow an IBM model-40 computer to segregate off its memory and allow up to 15 users to use the computer independently at once \citep{Lindquist1966}. Each user would see their own abstract Operating System, separate from the others. Whilst virtualisation has continued in its development from this point onwards, the core functionality and architecture behind Hardware Virtualisation, remain much the same.

Each of these individual logical (as opposed to physical) devices is called a `virtual machine'.

\subsection{Hardware Virtualisation}
\label{subsec:HardwareVirtualisation}
There are a number of different types of virtualisation, which can open the scope for what can and can not be technically classed as a virtual machine. For the purpose of this report the term `virtualisation' will refer to specifically `hardware based virtualisation', whereby a `virtual machine' is an operating system running on top of another operating system, with the virtualisation task itself being controlled by a `hypervisor' (This is explained in more detail in the next subsection: \ref{subsec:hypervisor}) .

This is an important definition, as often times containerisation (subsection \ref{sec:containerisation}) can be viewed as a distinguished \emph{form} of virtualisation, so for the purposes of this report, the two definitions must be distinguished as separate things, much like in the report ``Autonomic Orchestration of Containers: Problem Definition and Research Challenges'' \citep{casalicchio2016}, whereby a clear defined difference between Hardware Virtualisation and Containers is made.

\subsection{Hypervisor}
\label{subsec:hypervisor}
Hardware Virtualisation relies on an underlying software that runs on the already existing OS in order to manage each instance/OS. This software can have a number of different names depending on the origin of the work, and the context. In early work on virtualisation, this software was often referred to simply as a ``control program'' \citep{creasy1981}, but for the purposes of this research, this software will be referred to as a `Hypervisor'.

Hypervisor is often times the preferred term in practical settings, such as in VMware's online Glossary \citep{vmwareHypervisor}, where the software that controls a virtual machine is defined as such.

\section{The workings of virtualisation}
Virtualisation works


\chapter{Review of Containerisation and what it does}
\section{Terminology \& Definitions}

\subsection{Containerisation}
\label{subsec:containerisation}
Containerisation has become the de-facto term to describe what could also be described as OS-level virtualisation. For the purposes of this report, I will be referring to this technology only as Containerisation, and each individual instance as a container (instead of virtual machine). This is the same approach towards defining containers as taken by Dua et al \citep{dua14} when they have made their own distinction between Containers and Virtual Machines.

\subsection{Container Engine}
\label{Container Engine}
What a hypervisor is to a virtual machine, a container engine is to a container. A container engine sits on the base operating system, much the same as a hypervisor. Where a difference is found however, is in the way it interacts with the base operating system.

Whilst a hypervisor works by running a full operating system on top of the existing one, a container engine works without that upper operating system by using the base operating system as the OS component for each container. Segregation of containers and resource allocation is simply managed by the container engine, so that each container is allocated resources. This can be done dynamically or be static, depending on the use-case.

\section{Developments in containerisation technology}

\subsection{Docker}
A now ever more popular implementation of container technology is a software known as Docker. This software is primarily used (and aimed at) app developers, who can use the platform to quickly create and deploy applications for businesses. The use of containers is supposed to make managing these applications much easier, and ensures compatibility along the whole development process.
Datanyze (a technology market usage group) report that Docker is currently the second most used Containerisation platform, with 25.34\% market share in Containerisation \citep{datanyze}. 

Docker's Container engine is aptly named Docker Engine, and utilises a client-server architecture \citep[Section: Docker architecture]{DockerOverview}. The server portion of the Docker System is known as the `docker daemon', the Client uses a command line interface to interact with one or more docker daemons. The client and daemon communicate using a `REST API' \citep[Section: The Docker daemon]{DockerOverview}. REST (Representational State Transfer) provides an architecture for web services \citep{W3Architecture2004} that allows them to communicate. The protocols within REST are stateless, this means there is no set `state' or session control within the protocol. REST API being used as the communication method between the Docker Daemon and the Client means that each command sent to a daemon can be understood as it is, without the need for any outside context to the command being sent.

The Docker Daemon manages Docker the various `Objects' \citep[Section: Docker objects]{DockerOverview} required for a full Docker system. These include the containers, the images (Docker images are the instruction sets for Docker containers, not to be confused with OS images) and the Registry, which acts as a storage for the Docker images.


\chapter{System design and definition}
\subsection{Maintaining scientific method}
To ensure that results are scientific, variables must be controlled between both of the systems. The first step in this, is ensuring that the topology and configurations for both systems are the same. This can be done by copying the configuration files from one system to the other, ensuring that the system works in the same way for both systems. As the underlying operating system should be a version of Linux for both the virtual machine and the Docker system, this should be relatively easy.

To further ensure that variables are controlled, we need to ensure that the same benchmarks are maintained throughout the testing process, when being used on the \emph{same part of the system}. This means that if one benchmark is used to measure, for example, network latency on a web-server, then the same benchmark should be used to measure the network latency on that same web-server on the mirrored system. It may be necessary to use different benchmarks across the whole system, but this is acceptable as long as all testing is done to a parallel across both systems. The benchmarks to be used will be discussed in more detail in subsection \ref{sub:Benchmarking} (Benchmarking).

\subsection{LAMP System}
In order to make sure that the system is as accurate tom a real-world system as possible, a full LAMP topology will need to be implemented for both the Docker system and the Virtual Machine system. LAMP is the acronym of Linux, Apache, MySQL and PHP, whilst this can technically be run on one system, it is common to separate various functions out onto different logical machines, this generally makes management of these systems easier, and often more streamlined.

\subsection{Benchmarking}
\label{sub:Benchmarking}
Benchmarking software and tools are designed to create a standard output measurement for performance of a computer-based system\citep{fleming1986}.

There are a great number of benchmarking tools available to me for this research, but generally these can be split in discussion along lines of what exactly they are designed to measure. The main split for this research, being the measuring of base compute performance, and of network performance.

\subsubsection{Base Computing Performance}
Base computing performance in this case relates to the performance as a result of the computers ability to process information, and at what rate. Whilst this is tied directly to the processor, RAM, and other hardware, the Operating system itself can also have a large affect on the performance of a system, as it will always take up an amount of utilisation over time. This effect is known as `operating system overhead'. Based on previous research on containers and virtual machines it can be hypothesised that the total Operating System overhead for a container-based system will be smaller than that of Virtual Machines \emph{(when using the same operating system)}. This is simply due to the way that containers utilise one OS for their function (as discussed in subsection \ref{Container Engine}).


\subsection{DNS}

\subsection{Webserver}

\subsection{Intranet}

\chapter{How will the system be measured}
%Talk about benchmarks.